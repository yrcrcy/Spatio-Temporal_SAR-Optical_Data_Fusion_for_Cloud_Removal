{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2QD3exLVHGp"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8FM6nMVVFSt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqD9XIbPdAIJ"
   },
   "outputs": [],
   "source": [
    "def get_images_path(path, satellite):\n",
    "    '''\n",
    "        Returns a list of paths of images and a list of names of zones. \n",
    "        Satellite must be 'sen1' or 'sen2'.\n",
    "        Path must be the directory with 'sen1' and 'sen2' subdirectories inside.\n",
    "    '''\n",
    "    path = os.path.join(path, satellite)\n",
    "    images_path = []\n",
    "    zones = os.listdir(path)\n",
    "\n",
    "    for zone in zones:\n",
    "        zone_path = os.path.join(path, zone)\n",
    "        images = os.listdir(zone_path)\n",
    "        \n",
    "        for image in images:\n",
    "            image_path = os.path.join(zone_path, image)\n",
    "            images_path.append(image_path)\n",
    "            \n",
    "    images_path.sort()\n",
    "    \n",
    "    return images_path, zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqR-BE0NvSKu"
   },
   "outputs": [],
   "source": [
    "def split_S2_images(s2_paths):\n",
    "    '''\n",
    "        Splits the list of Sentinel-2 images in RGB images and cloud masks.\n",
    "        The path of the images must contains 'RGB' or 'CM'.\n",
    "    '''\n",
    "    cloud_mask = []\n",
    "    rgb = []\n",
    "    \n",
    "    for p in s2_paths:\n",
    "        if \"RGB\" in p:\n",
    "            rgb.append(p)\n",
    "        elif \"CM\" in p:\n",
    "            cloud_mask.append(p)\n",
    "    \n",
    "    return rgb, cloud_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTdtoiDUVRRR",
    "outputId": "261b5ba6-d665-4dd2-9dcb-d9cad2d202d8"
   },
   "outputs": [],
   "source": [
    "#Import the dataset \n",
    "dataset_path = '/content/drive/My Drive/timeseries_dataset'\n",
    "s2_paths, s2_zones = get_images_path(dataset_path, 'sen2')\n",
    "s1_images, s1_zones = get_images_path(dataset_path, 'sen1')\n",
    "s2_images, cloud_masks = split_S2_images(s2_paths)\n",
    "\n",
    "print(len(s2_images), len(s1_images))\n",
    "print(len(s2_zones), len(s1_zones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VDOaELt6SNt"
   },
   "source": [
    "#Preprocess phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3vzqvy7xcvl"
   },
   "outputs": [],
   "source": [
    "def get_s1_image(image_path):\n",
    "    '''\n",
    "        Returns an grayscale image (VV Sentinel-1) using a path.\n",
    "        Image path must be the full path of an grayscale (VV) image (tif format).\n",
    "    '''\n",
    "\n",
    "    dataset = rasterio.open(image_path)\n",
    "    if dataset.shape != (256, 256):\n",
    "      vv = dataset.read(1, out_shape=(256, 256))\n",
    "    else:\n",
    "      vv = dataset.read(1)\n",
    "    dataset.close()\n",
    "    \n",
    "    #vv = 10 * np.log10(vv)\n",
    "    vv = np.clip(vv, -30, 15)\n",
    "\n",
    "    #Normalization in [-1, 1]\n",
    "    vv = 2 * ((vv - vv.min())/(vv.max() - vv.min())) - 1\n",
    "    #Normalization in [0, 1]\n",
    "    #vv = (vv - vv.min())/(vv.max() - vv.min())\n",
    "    \n",
    "    return vv.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZrG50PKxU49"
   },
   "outputs": [],
   "source": [
    "def get_s2_image(image_path):\n",
    "    '''\n",
    "        Returns an RGB image using a path.\n",
    "        Image path must be the full path of an RGB image (tif format).\n",
    "    '''\n",
    "    dataset = rasterio.open(image_path)\n",
    "    if dataset.shape != (256, 256):\n",
    "      r = dataset.read(1, out_shape=(256, 256))\n",
    "      g = dataset.read(2, out_shape=(256, 256))\n",
    "      b = dataset.read(3, out_shape=(256, 256))\n",
    "    else:\n",
    "      r = dataset.read(1)\n",
    "      g = dataset.read(2)\n",
    "      b = dataset.read(3)\n",
    "    dataset.close()\n",
    "    \n",
    "    #RGB composite\n",
    "    rgb = np.zeros((r.shape[0], r.shape[1], 3))\n",
    "    rgb[..., 0] = r\n",
    "    rgb[..., 1] = g\n",
    "    rgb[..., 2] = b\n",
    "    \n",
    "    #Normalization in [-1, 1]\n",
    "    rgb = 2 * ((rgb - rgb.min())/(rgb.max() - rgb.min())) - 1\n",
    "    #Normalization in [0, 1]\n",
    "    #rgb = (rgb - rgb.min())/(rgb.max() - rgb.min())\n",
    "    \n",
    "    return rgb.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTVYSzmJMERw"
   },
   "source": [
    "# Model&Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Ew19zc4MOk9",
    "outputId": "e9892129-f5f1-4e47-86f7-921788a850c4"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from numpy import zeros, ones\n",
    "from numpy.random import randint\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.initializers import RandomNormal\n",
    "from tensorflow.python.keras.models import Model, Input\n",
    "from tensorflow.python.keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, Activation, Concatenate, Dropout, BatchNormalization\n",
    "from matplotlib import pyplot\n",
    "from skimage import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVKZ9MQhMS_G"
   },
   "outputs": [],
   "source": [
    "#Discriminator model\n",
    "def define_discriminator(image_shape_sar, image_shape_opt):\n",
    "  init = RandomNormal(stddev=0.02)\n",
    "  in_src_image = Input(shape=image_shape_sar)\n",
    "  in_target_image = Input(shape=image_shape_opt)\n",
    "  merged = Concatenate()([in_src_image, in_target_image])\n",
    "  \n",
    "  d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged) \n",
    "  d = LeakyReLU(alpha=0.2)(d)\n",
    "  \n",
    "  d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "  d = BatchNormalization()(d)\n",
    "  d = LeakyReLU(alpha=0.2)(d)\n",
    "  \n",
    "  d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "  d = BatchNormalization()(d)\n",
    "  d = LeakyReLU(alpha=0.2)(d)\n",
    "  \n",
    "  d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "  d = BatchNormalization()(d)\n",
    "  d = LeakyReLU(alpha=0.2)(d)\n",
    "  \n",
    "  d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "  d = BatchNormalization()(d)\n",
    "  d = LeakyReLU(alpha=0.2)(d)\n",
    "  \n",
    "  d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "  patch_out = Activation('sigmoid')(d)\n",
    "  \n",
    "  model = Model([in_src_image, in_target_image], patch_out)       \n",
    "  opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "  model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGTvax10OY5V"
   },
   "outputs": [],
   "source": [
    "#Generator model\n",
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    " \n",
    "\tif batchnorm:\n",
    "\t\tg = BatchNormalization()(g, training=True)\n",
    "\n",
    "\tg = LeakyReLU(alpha=0.2)(g)\n",
    " \n",
    "\treturn g\n",
    " \n",
    "\n",
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\tg = BatchNormalization()(g, training=True)\n",
    "\t\n",
    "\tif dropout:\n",
    "\t\tg = Dropout(0.5)(g, training=True)\n",
    "\t\n",
    "\tg = Concatenate()([g, skip_in])\n",
    "\tg = Activation('relu')(g)\n",
    " \n",
    "\treturn g\n",
    " \n",
    " \n",
    "def define_generator(image_shape=(256,256,1)):\n",
    "\t\n",
    " init = RandomNormal(stddev=0.02)\n",
    " in_image = Input(shape=image_shape)\n",
    "\n",
    " e1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    " e2 = define_encoder_block(e1, 128)\n",
    " e3 = define_encoder_block(e2, 256)\n",
    " e4 = define_encoder_block(e3, 512)\n",
    " e5 = define_encoder_block(e4, 512)\n",
    " e6 = define_encoder_block(e5, 512)\n",
    " e7 = define_encoder_block(e6, 512)\n",
    "\t\n",
    " b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    " b = Activation('relu')(b)\n",
    "\t\n",
    " d1 = decoder_block(b, e7, 512)\n",
    " d2 = decoder_block(d1, e6, 512)\n",
    " d3 = decoder_block(d2, e5, 512)\n",
    " d4 = decoder_block(d3, e4, 512, dropout=False)\n",
    " d5 = decoder_block(d4, e3, 256, dropout=False)\n",
    " d6 = decoder_block(d5, e2, 128, dropout=False)\n",
    " d7 = decoder_block(d6, e1, 64, dropout=False)\n",
    "\n",
    " g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    " out_image = Activation('tanh')(g)\n",
    "\n",
    " model = Model(in_image, out_image)\n",
    "\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjXGZXquPQDy"
   },
   "outputs": [],
   "source": [
    "#GAN model\n",
    "def define_gan(g_model, d_model, image_shape_sar):\n",
    "\t\n",
    " d_model.trainable = False\n",
    " in_src = Input(shape=image_shape_sar)\n",
    " \n",
    " gen_out = g_model(in_src)\n",
    " dis_out = d_model([in_src, gen_out])   \n",
    "\n",
    " model = Model(in_src, [dis_out, gen_out])   \n",
    " opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    " model.compile(loss=['binary_crossentropy', 'mse'], optimizer=opt, loss_weights=[1, 100])\n",
    "\t\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpC1J21mQsLh"
   },
   "outputs": [],
   "source": [
    "#Prepare data: the label y is 0 for fake samples and 1 for real samples\n",
    "def select_batch(s1data, s2data, n_samples, patch_shape):\n",
    " X1=[]\n",
    " X2=[]\n",
    " ix = randint(0, 7983, n_samples)\n",
    " for elem in ix:\n",
    "\t s1image = get_s1_image(s1data[elem])\n",
    "\t s1image = np.reshape(s1image, (1,256,256,1))\n",
    "\t s1image = despeckle_model.predict(s1image)\n",
    "\t #X1.append(get_s1_image(s1data[elem]))\n",
    "\t X1.append(s1image)\n",
    "\t X2.append(get_s2_image(s2data[elem]))\n",
    " y = ones((n_samples, patch_shape, patch_shape, 1))\n",
    " return [X1, X2], y\n",
    " \n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "\tX = g_model.predict(samples)\n",
    "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "\treturn X, y\n",
    "\n",
    "\n",
    "#Save the model and plot results \n",
    "def summarize_performance(step, g_model, s1data, s2data, n_samples=3):\n",
    " #f = open(\"/content/drive/My Drive/ESA/GAN/file.txt\", \"a\")\n",
    " #[X_realA, X_realB], _ = select_batch(s1data, s2data, n_samples, 1)\n",
    " #X_realA = np.array(X_realA).reshape(np.array(X_realA).shape[0], 256, 256, 1)\n",
    " #X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    " #X_realA = np.array(X_realA).reshape(np.array(X_realA).shape[0], 256, 256)\n",
    " \n",
    " #Scale all pixels from [-1,1] to [0,1]\n",
    " #X_realA = (np.array(X_realA) + 1) / 2.0\n",
    " #X_realB = (np.array(X_realB) + 1) / 2.0\n",
    " #X_fakeB = (np.array(X_fakeB) + 1) / 2.0\n",
    "\n",
    " '''\n",
    " for i in range(n_samples):\n",
    "\t pyplot.subplot(3, n_samples, 1 + i)\n",
    "\t pyplot.axis('off')\n",
    "\t pyplot.imshow(X_realA[i])\n",
    "\t\n",
    " for i in range(n_samples):\n",
    "\t pyplot.subplot(3, n_samples, 1 + n_samples + i)\n",
    "\t pyplot.axis('off')\n",
    "\t pyplot.imshow(X_fakeB[i])\n",
    "\t\n",
    " for i in range(n_samples):\n",
    "\t pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "\t pyplot.axis('off')\n",
    "\t pyplot.imshow(X_realB[i])\n",
    " '''\n",
    "\t \n",
    "\t #p = metrics.peak_signal_noise_ratio(X_realB[i], X_fakeB[i])\n",
    "\t #f.write(\"Step \" + str(step) + \": sample n° \" + str(i) + \" psnr value -> \" + str(p) + \"\\n\")\n",
    "\t #s = metrics.structural_similarity(X_realB[i], X_fakeB[i], multichannel=True)\n",
    "\t #f.write(\"Step \" + str(step) + \": sample n° \" + str(i) + \" ssim value -> \" + str(s) + \"\\n\")\n",
    "\t\n",
    " #filename1 = 'plot_%06d.png' % (step+1)\n",
    " #pyplot.savefig('/content/drive/My Drive/ESA/GAN/' + filename1)\n",
    " #pyplot.close()\n",
    "\n",
    " filename2 = 'model_%06d.h5' % (step+1)\n",
    " g_model.save('/content/drive/My Drive/ESA/GAN/' + filename2)\n",
    " print('>Saved: %s' % (filename2))\n",
    " #print('>Saved: %s and %s' % (filename1, filename2))\n",
    " #f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzZbJMS0P4fX"
   },
   "outputs": [],
   "source": [
    "#Train phase\n",
    "def train(d_model, g_model, gan_model, s1data, s2data, n_epochs=300, n_batch=32):\n",
    "\tn_patch = d_model.output_shape[1]\n",
    "\tbatch_per_epoch = int(len(s1data) / n_batch)\n",
    "\tn_steps = batch_per_epoch * n_epochs\n",
    "\n",
    "\tfor i in range(n_steps):\n",
    "\t\t[X_realA, X_realB], y_real = select_batch(s1data, s2data, n_batch, n_patch)\n",
    "\t\tX_realA = np.array(X_realA).reshape(np.array(X_realA).shape[0], 256, 256, 1)\n",
    "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "\n",
    "\t\td_loss1 = d_model.train_on_batch([np.array(X_realA), np.array(X_realB)], y_real)\n",
    "\t\td_loss2 = d_model.train_on_batch([np.array(X_realA), np.array(X_fakeB)], y_fake)\n",
    "\t\tg_loss, _, _ = gan_model.train_on_batch(np.array(X_realA), [y_real, np.array(X_realB)])\n",
    "\n",
    "\t\tprint(\"Step: \"+ str(i+1) +\" -> d1_loss: \" + str(d_loss1) + \" | d2_loss: \" + str(d_loss2) + \" | g_loss: \" + str(g_loss))\n",
    "\t\tif ((i+1) % 500 == 0) or (i == 0) or (i == n_steps-1): \n",
    "\t\t\tsummarize_performance(i, g_model, s1data, s2data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7_CJRktNNju",
    "outputId": "b056b662-6c8b-4091-cfa1-fef7123d9939"
   },
   "outputs": [],
   "source": [
    "image_shape_sar = (256, 256, 1)\n",
    "image_shape_opt = (256, 256, 3)\n",
    "\n",
    "despeckle_model = load_model('/content/drive/My Drive/ESA/GAN/despeckling.h5')\n",
    "discriminator_model = define_discriminator(image_shape_sar, image_shape_opt)\n",
    "#generator_model = define_generator(image_shape_sar)\n",
    "generator_model = load_model('/content/drive/My Drive/ESA/GAN/Weights/model_014000.h5')\n",
    "gan_model = define_gan(generator_model, discriminator_model, image_shape_sar)\n",
    "\n",
    "train(discriminator_model, generator_model, gan_model, s1_images, s2_images)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "GAN_forAleDataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
